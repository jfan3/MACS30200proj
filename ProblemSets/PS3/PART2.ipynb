{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras.regularizers import l2, l1\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "### i).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "N = 100\n",
    "batchsize = 512\n",
    "epoch_count = 200\n",
    "split1 = 1/6\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(512, activation='relu'))\n",
    "network.add(layers.Dense(512, activation='relu'))\n",
    "network.add(layers.Dense(512, activation='relu'))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "train_images = train_images.reshape( (60000, 28 * 28) )\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape( (10000, 28 * 28) )\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "fit = network.fit(train_images, train_labels, epochs=epoch_count, batch_size=batchsize, validation_split=split1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error = fit.history['loss']\n",
    "training_acc = fit.history['acc']\n",
    "vali_error = fit.history['val_loss']\n",
    "vali_acc = fit.history['val_acc']\n",
    "x_vals = np.arange(1, epoch_count+1)\n",
    "\n",
    "plt.plot(x_vals, training_acc, 'r',label='Training Accuracy')\n",
    "plt.plot(x_vals, vali_acc, 'b',label='Validation Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy by Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.plot(x_vals, training_error, 'r',label='Training Accuracy')\n",
    "plt.plot(x_vals, vali_error, 'r',label='Validation Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Error by Epoch\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal epoch is 3\n"
     ]
    }
   ],
   "source": [
    "index_min = np.argmin(vali_error)\n",
    "print(f\"The optimal epoch is {index_min}\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_network = models.Sequential()\n",
    "\n",
    "drop_network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "drop_network.add(layers.Dropout(0.5))\n",
    "\n",
    "drop_network.add(layers.Dense(512, activation='relu'))\n",
    "drop_network.add(layers.Dropout(0.5))\n",
    "\n",
    "drop_network.add(layers.Dense(512, activation='relu'))\n",
    "drop_network.add(layers.Dropout(0.5))\n",
    "\n",
    "drop_network.add(layers.Dense(512, activation='relu'))\n",
    "drop_network.add(layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "drop_network.add(layers.Dense(10, activation='softmax'))\n",
    "drop_network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "drop_fit = drop_network.fit(train_images, train_labels, epochs=epoch_count, batch_size=batchsize, validation_split=split1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_val_error = drop_fit.history['val_loss']\n",
    "drop_val_acc = drop_fit.history['val_acc']\n",
    "x_vals = np.arange(1, epoch_count+1)\n",
    "\n",
    "plt.plot(x_vals, drop_val_error,'r',label='Dropped')\n",
    "plt.plot(x_vals, vali_error,'b',label='Original')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Error\")\n",
    "plt.title(\"Validation Error by epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.plot(x_vals, drop_val_acc,'r',label='Dropped')\n",
    "plt.plot(x_vals, vali_acc,'b',label='Original')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Validation Accuracy by epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model is doing better. \n",
    "\n",
    "### iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build artchicture - L1 regularization# build  \n",
    "# build artchicture\n",
    "\n",
    "l1_network = models.Sequential()\n",
    "l1_network.add(layers.Dense(512, activation='relu', kernel_regularizer=l1(0.001), input_shape=(28 * 28,)))\n",
    "\n",
    "\n",
    "l1_network.add(layers.Dense(512, kernel_regularizer=l1(0.001), activation='relu'))\n",
    "l1_network.add(layers.Dense(512, kernel_regularizer=l1(0.001), activation='relu'))\n",
    "l1_network.add(layers.Dense(512, kernel_regularizer=l1(0.001), activation='relu'))\n",
    "\n",
    "l1_network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# build artchicture - L2 regularization\n",
    "l2_network = models.Sequential()\n",
    "l2_network.add(layers.Dense(512, activation='relu', kernel_regularizer=l2(0.001), input_shape=(28 * 28,)))\n",
    "\n",
    "\n",
    "l2_network.add(layers.Dense(512, kernel_regularizer=l2(0.001), activation='relu'))\n",
    "l2_network.add(layers.Dense(512, kernel_regularizer=l2(0.001), activation='relu'))\n",
    "l2_network.add(layers.Dense(512, kernel_regularizer=l2(0.001), activation='relu'))\n",
    "\n",
    "\n",
    "l2_network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# Fit the model# Fit th \n",
    "l1_network.compile(optimizer='rmsprop', loss='categorical_crossentropy',  metrics=['acc'])\n",
    "l1_fit = l1_network.fit(train_images, train_labels, epochs=epoch_count, batch_size=batchsize, validation_split=split1)\n",
    "\n",
    "l2_network.compile(optimizer='rmsprop', loss='categorical_crossentropy',  metrics=['acc'])\n",
    "l2_fit = l2_network.fit(train_images, train_labels, epochs=epoch_count, batch_size=batchsize, validation_split=split1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the training losses of all 4 models# Plot t \n",
    "l1_val_error = l1_fit.history['val_loss']\n",
    "l1_val_acc = l1_fit.history['val_acc']\n",
    "\n",
    "l2_val_error = l2_fit.history['val_loss']\n",
    "l2_val_acc = l2_fit.history['val_acc']\n",
    "\n",
    "plt.plot(x_vals, drop_val_error, label='Dropped' )\n",
    "plt.plot(x_vals, vali_error, label='Original')\n",
    "plt.plot(x_vals, l1_val_error, label='L1')\n",
    "plt.plot(x_vals, l2_val_error, label='L2')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation error\")\n",
    "plt.title(\"Validation error by Epoch across Models\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min1=np.min(drop_val_error)\n",
    "min2=np.min(vali_error)\n",
    "min3=np.min(l1_val_error)\n",
    "min4=np.min(l2_val_error)\n",
    "min1,min2,min3,min4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_epoch_count =  np.argmin(vali_error) + 1\n",
    "print(\"The optimal epoch for the main baseline model is:\", new_epoch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "full_fit = network.fit(train_images, train_labels, epochs=new_epoch_count, batch_size=batchsize)\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std \n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layer_list):\n",
    "    '''\n",
    "    The layer_list is a list of integers, each denoting a layer to\n",
    "    add with the corresponding number of nodes\n",
    "    '''\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    for node_count in layer_list:\n",
    "        model.add(layers.Dense(node_count, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def cross_validate(model_structure):\n",
    "    '''\n",
    "    Given a model structure, returns the avg MSE over 10 k-fold\n",
    "    cross validation training\n",
    "    \n",
    "    This facilitates rapid testing of models\n",
    "    '''\n",
    "    \n",
    "    kf = KFold(n_splits = k)\n",
    "    cur_fold = 0\n",
    "    for train_index, test_index in kf.split(train_data):\n",
    "        cur_fold +=1 \n",
    "\n",
    "        # Partition the data\n",
    "        x_train, x_test = train_data[train_index], train_data[test_index]\n",
    "        y_train, y_test = train_targets[train_index], train_targets[test_index]\n",
    "\n",
    "\n",
    "        model = build_model(model_structure)\n",
    "        model.fit(x_train, y_train, epochs=num_epochs, batch_size=1)\n",
    "        val_mse, val_mae = model.evaluate(x_test, y_test)\n",
    "        all_scores.append(val_mse)\n",
    "        print(\"K-FOLD = {}| MSE = {}\".format(cur_fold, val_mse ))\n",
    "\n",
    "    mean_score = np.mean(all_scores)\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k = 10\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 5\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 15s 40ms/step - loss: 498.5878 - mean_absolute_error: 20.3623\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 233.9675 - mean_absolute_error: 12.8176\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 76.3699 - mean_absolute_error: 6.1440\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 44.8823 - mean_absolute_error: 4.5857\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 34.2434 - mean_absolute_error: 3.9474\n",
      "41/41 [==============================] - 0s 608us/step\n",
      "K-FOLD = 1| MSE = 59.19306027016989\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 476.9468 - mean_absolute_error: 19.6879\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 178.8360 - mean_absolute_error: 10.5650\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 58.0094 - mean_absolute_error: 4.9907\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 39.6259 - mean_absolute_error: 4.1126\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 32.2537 - mean_absolute_error: 3.6557\n",
      "41/41 [==============================] - 0s 694us/step\n",
      "K-FOLD = 2| MSE = 8.283426866298768\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 501.1427 - mean_absolute_error: 20.4312\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 265.2976 - mean_absolute_error: 13.7224\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 84.3328 - mean_absolute_error: 6.1857\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 52.5705 - mean_absolute_error: 4.6600\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 42.8708 - mean_absolute_error: 4.1963\n",
      "41/41 [==============================] - 0s 810us/step\n",
      "K-FOLD = 3| MSE = 43.50006159340463\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 455.3003 - mean_absolute_error: 19.2460\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 183.4429 - mean_absolute_error: 10.6130\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 64.0943 - mean_absolute_error: 5.2716\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 41.9113 - mean_absolute_error: 4.1165\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 33.1155 - mean_absolute_error: 3.5987\n",
      "41/41 [==============================] - 0s 919us/step\n",
      "K-FOLD = 4| MSE = 27.870015772377574\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 463.0388 - mean_absolute_error: 19.3514\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 163.5161 - mean_absolute_error: 9.7787\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 67.2748 - mean_absolute_error: 5.4282\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 45.2957 - mean_absolute_error: 4.4180\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 37.1925 - mean_absolute_error: 3.9203\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "K-FOLD = 5| MSE = 14.442051887512207\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 445.1553 - mean_absolute_error: 18.9459\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 171.0038 - mean_absolute_error: 10.0854\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 73.6246 - mean_absolute_error: 5.8023\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 46.9975 - mean_absolute_error: 4.4679\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 37.2098 - mean_absolute_error: 3.9147\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "K-FOLD = 6| MSE = 20.756350326538087\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 473.8505 - mean_absolute_error: 20.0213\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 205.0497 - mean_absolute_error: 11.9780\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 73.2632 - mean_absolute_error: 5.8489\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 43.9010 - mean_absolute_error: 4.2351\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 35.8727 - mean_absolute_error: 3.7509\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "K-FOLD = 7| MSE = 17.35055923461914\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 455.8760 - mean_absolute_error: 19.3986\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 191.0759 - mean_absolute_error: 11.1794\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 52.4608 - mean_absolute_error: 4.8525\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 33.7938 - mean_absolute_error: 4.0300\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 26.7221 - mean_absolute_error: 3.5560\n",
      "40/40 [==============================] - 0s 1ms/step\n",
      "K-FOLD = 8| MSE = 67.1977325439453\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 414.2968 - mean_absolute_error: 18.3755\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 146.6494 - mean_absolute_error: 9.4441\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 51.6157 - mean_absolute_error: 4.8011\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 37.2254 - mean_absolute_error: 4.0474\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 31.9917 - mean_absolute_error: 3.6560\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "K-FOLD = 9| MSE = 62.54746704101562\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 435.9461 - mean_absolute_error: 18.9485\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 152.9605 - mean_absolute_error: 9.5534\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 55.6798 - mean_absolute_error: 4.9389\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 40.0796 - mean_absolute_error: 4.1900\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 32.9519 - mean_absolute_error: 3.7222\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "K-FOLD = 10| MSE = 25.13881206512451\n",
      "Layer 1 has 40 nodes - yields MSE = 34.627953760100574\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 377.5547 - mean_absolute_error: 17.4653\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 99.8833 - mean_absolute_error: 7.3587\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 38.5672 - mean_absolute_error: 4.1400\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 29.0408 - mean_absolute_error: 3.6391\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 24.9971 - mean_absolute_error: 3.3776\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "K-FOLD = 1| MSE = 41.873653179261744\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 436.5153 - mean_absolute_error: 18.5532\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 134.9264 - mean_absolute_error: 8.7917\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 52.7430 - mean_absolute_error: 4.8324\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 35.9251 - mean_absolute_error: 3.9042\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 28.7211 - mean_absolute_error: 3.5021\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "K-FOLD = 2| MSE = 9.012651350440049\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 463.4795 - mean_absolute_error: 19.4770\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 185.6907 - mean_absolute_error: 10.6936\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 66.5464 - mean_absolute_error: 5.2867\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 43.4072 - mean_absolute_error: 4.2691\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 33.6435 - mean_absolute_error: 3.7529\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "K-FOLD = 3| MSE = 28.7782294575761\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 458.3610 - mean_absolute_error: 19.1111\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 166.6001 - mean_absolute_error: 10.0814\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 51.3859 - mean_absolute_error: 4.7755\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 38.5318 - mean_absolute_error: 4.0934\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 31.4271 - mean_absolute_error: 3.6666\n",
      "41/41 [==============================] - 0s 2ms/step\n",
      "K-FOLD = 4| MSE = 28.77155080655726\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 425.0748 - mean_absolute_error: 18.3187\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 143.2760 - mean_absolute_error: 8.9345\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 56.7829 - mean_absolute_error: 5.0179\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 39.9674 - mean_absolute_error: 4.0663\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 32.4771 - mean_absolute_error: 3.6703\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "K-FOLD = 5| MSE = 10.92073106765747\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 454.2382 - mean_absolute_error: 19.1049\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 158.6148 - mean_absolute_error: 9.2707\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 62.5399 - mean_absolute_error: 5.1291\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 46.7040 - mean_absolute_error: 4.3785\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 38.6101 - mean_absolute_error: 3.9352\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "K-FOLD = 6| MSE = 15.02285556793213\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 448.3694 - mean_absolute_error: 19.0868\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 158.6607 - mean_absolute_error: 9.6897\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 49.9572 - mean_absolute_error: 4.5283\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 36.6741 - mean_absolute_error: 3.9520\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 30.9124 - mean_absolute_error: 3.5533\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "K-FOLD = 7| MSE = 14.68396816253662\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 454.9727 - mean_absolute_error: 19.5419\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 146.9689 - mean_absolute_error: 9.7962\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 40.2079 - mean_absolute_error: 4.2570\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 31.5930 - mean_absolute_error: 3.7802\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 26.9084 - mean_absolute_error: 3.4669\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "K-FOLD = 8| MSE = 73.59912719726563\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 432.6818 - mean_absolute_error: 18.7387\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 138.9075 - mean_absolute_error: 9.3463\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 49.0406 - mean_absolute_error: 4.7244\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 35.9841 - mean_absolute_error: 3.9188\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 30.7943 - mean_absolute_error: 3.5703\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "K-FOLD = 9| MSE = 63.33437776565552\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 419.8036 - mean_absolute_error: 18.1470\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 125.3278 - mean_absolute_error: 8.2608\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 53.4715 - mean_absolute_error: 4.9061\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 38.9030 - mean_absolute_error: 4.0790\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 32.4925 - mean_absolute_error: 3.7321\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "K-FOLD = 10| MSE = 19.744822406768797\n",
      "Layer 1 has 50 nodes - yields MSE = 32.60107522813285\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 405.5216 - mean_absolute_error: 18.1471\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 108.3558 - mean_absolute_error: 7.8147\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 45.0052 - mean_absolute_error: 4.5686\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 32.9667 - mean_absolute_error: 3.8508\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 27.5392 - mean_absolute_error: 3.5117\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "K-FOLD = 1| MSE = 52.197998442300936\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 476.0269 - mean_absolute_error: 19.9410\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 160.8344 - mean_absolute_error: 9.9716\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 56.4057 - mean_absolute_error: 5.0259\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 39.8536 - mean_absolute_error: 4.0842\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 33.0736 - mean_absolute_error: 3.6998\n",
      "41/41 [==============================] - 0s 3ms/step\n",
      "K-FOLD = 2| MSE = 8.698708790104563\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 431.8510 - mean_absolute_error: 18.6292\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 141.7084 - mean_absolute_error: 9.0021\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 46.6719 - mean_absolute_error: 4.5157\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 33.8959 - mean_absolute_error: 3.8984\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 28.0825 - mean_absolute_error: 3.5452\n",
      "41/41 [==============================] - 0s 4ms/step\n",
      "K-FOLD = 3| MSE = 26.729814575939642\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 469.4917 - mean_absolute_error: 19.7517\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 172.7366 - mean_absolute_error: 10.3788\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 53.6911 - mean_absolute_error: 4.7132\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 37.3571 - mean_absolute_error: 3.9195\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 30.2336 - mean_absolute_error: 3.4438\n",
      "41/41 [==============================] - 0s 4ms/step\n",
      "K-FOLD = 4| MSE = 27.11394528644841\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 4ms/step - loss: 402.0569 - mean_absolute_error: 17.8480\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 109.0654 - mean_absolute_error: 7.2997\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 51.9303 - mean_absolute_error: 4.5504\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 40.7003 - mean_absolute_error: 4.0142\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 33.8442 - mean_absolute_error: 3.6980\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "K-FOLD = 5| MSE = 12.147106456756593\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 1s 4ms/step - loss: 444.4832 - mean_absolute_error: 18.8966\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 123.4277 - mean_absolute_error: 8.4230\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 44.4996 - mean_absolute_error: 4.3430\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 34.8213 - mean_absolute_error: 3.7804\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 29.7858 - mean_absolute_error: 3.4464\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "K-FOLD = 6| MSE = 12.959951400756836\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 4ms/step - loss: 435.2897 - mean_absolute_error: 18.7503\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 136.5617 - mean_absolute_error: 8.6345\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 57.0925 - mean_absolute_error: 5.0177\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 42.5035 - mean_absolute_error: 4.2391\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 35.1895 - mean_absolute_error: 3.8457\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "K-FOLD = 7| MSE = 17.650896072387695\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 4ms/step - loss: 379.9441 - mean_absolute_error: 17.6004\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 91.2691 - mean_absolute_error: 7.0444\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 37.3289 - mean_absolute_error: 4.1730\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 27.9624 - mean_absolute_error: 3.6077\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 24.0531 - mean_absolute_error: 3.3101\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "K-FOLD = 8| MSE = 68.58902587890626\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 4ms/step - loss: 423.6814 - mean_absolute_error: 18.3821\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 133.7684 - mean_absolute_error: 8.5238\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 48.7697 - mean_absolute_error: 4.6663\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 38.2260 - mean_absolute_error: 4.0519\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 31.6132 - mean_absolute_error: 3.6851\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "K-FOLD = 9| MSE = 71.54798469543456\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 4ms/step - loss: 402.2048 - mean_absolute_error: 17.7307\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 119.7413 - mean_absolute_error: 7.8361\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 53.9567 - mean_absolute_error: 4.7462\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 36.9695 - mean_absolute_error: 3.9447\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 30.0138 - mean_absolute_error: 3.4850\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "K-FOLD = 10| MSE = 19.95448169708252\n",
      "Layer 1 has 60 nodes - yields MSE = 32.320380595292505\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 403.0724 - mean_absolute_error: 17.9010\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 97.9111 - mean_absolute_error: 7.1519\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 41.9196 - mean_absolute_error: 4.3872\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 30.4796 - mean_absolute_error: 3.6953\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 25.7887 - mean_absolute_error: 3.3491\n",
      "41/41 [==============================] - 0s 5ms/step\n",
      "K-FOLD = 1| MSE = 47.69107107999848\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 400.9812 - mean_absolute_error: 17.9299\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 97.2188 - mean_absolute_error: 7.1373\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 40.5783 - mean_absolute_error: 4.2646\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 30.7792 - mean_absolute_error: 3.6946\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 26.8109 - mean_absolute_error: 3.4237\n",
      "41/41 [==============================] - 0s 5ms/step\n",
      "K-FOLD = 2| MSE = 10.05769727288223\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 380.5134 - mean_absolute_error: 17.5217\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 107.4765 - mean_absolute_error: 7.4669\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 45.6271 - mean_absolute_error: 4.3821\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 33.9128 - mean_absolute_error: 3.6735\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 29.2448 - mean_absolute_error: 3.3706\n",
      "41/41 [==============================] - 0s 5ms/step\n",
      "K-FOLD = 3| MSE = 21.853258551620854\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 398.2639 - mean_absolute_error: 17.5878\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 107.9118 - mean_absolute_error: 7.2634\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 45.5408 - mean_absolute_error: 4.4202\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 32.8814 - mean_absolute_error: 3.6886\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 27.7198 - mean_absolute_error: 3.3514\n",
      "41/41 [==============================] - 0s 5ms/step\n",
      "K-FOLD = 4| MSE = 26.74483792374774\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 4ms/step - loss: 426.2705 - mean_absolute_error: 18.6218\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 123.3362 - mean_absolute_error: 8.2192\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 48.2017 - mean_absolute_error: 4.5388\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 35.8249 - mean_absolute_error: 3.9204\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 29.6405 - mean_absolute_error: 3.5644\n",
      "40/40 [==============================] - 0s 5ms/step\n",
      "K-FOLD = 5| MSE = 11.297471618652343\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 4ms/step - loss: 397.7293 - mean_absolute_error: 17.7033\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 101.3749 - mean_absolute_error: 6.9929\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 46.8063 - mean_absolute_error: 4.5099\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 35.7188 - mean_absolute_error: 3.8928\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 30.1930 - mean_absolute_error: 3.5124\n",
      "40/40 [==============================] - 0s 5ms/step\n",
      "K-FOLD = 6| MSE = 15.408991622924805\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 4ms/step - loss: 402.0807 - mean_absolute_error: 17.7916\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 104.9995 - mean_absolute_error: 7.1058\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 51.7783 - mean_absolute_error: 4.6611\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 38.0699 - mean_absolute_error: 4.0076\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 30.6994 - mean_absolute_error: 3.6070\n",
      "40/40 [==============================] - 0s 6ms/step\n",
      "K-FOLD = 7| MSE = 16.81261100769043\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 4ms/step - loss: 402.3178 - mean_absolute_error: 17.6913\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 83.9822 - mean_absolute_error: 6.5050\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 38.3261 - mean_absolute_error: 4.2019\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 27.4944 - mean_absolute_error: 3.5712\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 23.0110 - mean_absolute_error: 3.2521\n",
      "40/40 [==============================] - 0s 6ms/step\n",
      "K-FOLD = 8| MSE = 59.83131713867188\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 4ms/step - loss: 358.0555 - mean_absolute_error: 16.6250\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 78.0445 - mean_absolute_error: 6.2401\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 36.8880 - mean_absolute_error: 3.9968\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 28.3537 - mean_absolute_error: 3.4772\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 24.6294 - mean_absolute_error: 3.1918\n",
      "40/40 [==============================] - 0s 6ms/step\n",
      "K-FOLD = 9| MSE = 45.05887622833252\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 1s 4ms/step - loss: 407.8648 - mean_absolute_error: 18.0121\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 112.5953 - mean_absolute_error: 7.3882\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 50.7186 - mean_absolute_error: 4.5003\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 40.1809 - mean_absolute_error: 3.9558\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 34.2705 - mean_absolute_error: 3.6675\n",
      "40/40 [==============================] - 0s 6ms/step\n",
      "K-FOLD = 10| MSE = 18.554471969604492\n",
      "Layer 1 has 70 nodes - yields MSE = 31.073050556822523\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 382.2702 - mean_absolute_error: 17.3910\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 82.6878 - mean_absolute_error: 6.5177\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 37.6008 - mean_absolute_error: 4.1481\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 29.1969 - mean_absolute_error: 3.6160\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 25.3840 - mean_absolute_error: 3.2987\n",
      "41/41 [==============================] - 0s 7ms/step\n",
      "K-FOLD = 1| MSE = 48.93206596374512\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 419.3098 - mean_absolute_error: 18.4423\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 106.8765 - mean_absolute_error: 7.4144\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 46.7340 - mean_absolute_error: 4.3358\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 36.1526 - mean_absolute_error: 3.8442\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 30.7716 - mean_absolute_error: 3.5156\n",
      "41/41 [==============================] - 0s 6ms/step\n",
      "K-FOLD = 2| MSE = 8.127920360099978\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 385.6527 - mean_absolute_error: 17.5668\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 87.7650 - mean_absolute_error: 6.3956\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 36.9717 - mean_absolute_error: 3.9401\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 28.7096 - mean_absolute_error: 3.4496\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 25.1209 - mean_absolute_error: 3.2168\n",
      "41/41 [==============================] - 0s 7ms/step\n",
      "K-FOLD = 3| MSE = 19.863785790234076\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 399.5126 - mean_absolute_error: 17.5735\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 96.1502 - mean_absolute_error: 6.8958\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 47.3114 - mean_absolute_error: 4.4442\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 33.3761 - mean_absolute_error: 3.7087\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 27.3601 - mean_absolute_error: 3.3920\n",
      "41/41 [==============================] - 0s 6ms/step\n",
      "K-FOLD = 4| MSE = 27.01311660394436\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 4ms/step - loss: 388.3303 - mean_absolute_error: 17.1798\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 97.4682 - mean_absolute_error: 6.8370\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 49.5941 - mean_absolute_error: 4.5719\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 34.6796 - mean_absolute_error: 3.8621\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 28.9334 - mean_absolute_error: 3.4972\n",
      "40/40 [==============================] - 0s 7ms/step\n",
      "K-FOLD = 5| MSE = 11.40108642578125\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 4ms/step - loss: 419.3213 - mean_absolute_error: 18.1952\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 105.5926 - mean_absolute_error: 7.2790\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 48.9654 - mean_absolute_error: 4.5778\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 35.8730 - mean_absolute_error: 3.8561\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 29.1024 - mean_absolute_error: 3.4568\n",
      "40/40 [==============================] - 0s 7ms/step\n",
      "K-FOLD = 6| MSE = 13.951808166503906\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 4ms/step - loss: 423.6153 - mean_absolute_error: 18.2989\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 108.8429 - mean_absolute_error: 7.3852\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 50.8621 - mean_absolute_error: 4.5719\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 37.5618 - mean_absolute_error: 3.9345\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 31.2305 - mean_absolute_error: 3.5858\n",
      "40/40 [==============================] - 0s 7ms/step\n",
      "K-FOLD = 7| MSE = 14.22219123840332\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 4ms/step - loss: 358.8724 - mean_absolute_error: 16.8026\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 88.1047 - mean_absolute_error: 6.5294\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 36.4144 - mean_absolute_error: 4.0800\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 26.5097 - mean_absolute_error: 3.4064\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 21.8217 - mean_absolute_error: 3.1144\n",
      "40/40 [==============================] - 0s 7ms/step\n",
      "K-FOLD = 8| MSE = 65.55175476074218\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 4ms/step - loss: 348.1959 - mean_absolute_error: 16.2232\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 67.5689 - mean_absolute_error: 5.6286\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 39.8340 - mean_absolute_error: 4.1926\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 31.4933 - mean_absolute_error: 3.5617\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 27.0021 - mean_absolute_error: 3.2528\n",
      "40/40 [==============================] - 0s 8ms/step\n",
      "K-FOLD = 9| MSE = 55.050343132019044\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 368.5633 - mean_absolute_error: 16.5126\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 2ms/step - loss: 89.3936 - mean_absolute_error: 6.2452\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 44.2243 - mean_absolute_error: 4.3163\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 32.8932 - mean_absolute_error: 3.6306\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 26.8280 - mean_absolute_error: 3.3680\n",
      "40/40 [==============================] - 0s 7ms/step\n",
      "K-FOLD = 10| MSE = 17.977467632293703\n",
      "Layer 1 has 80 nodes - yields MSE = 30.50027124693335\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 2s 5ms/step - loss: 352.7192 - mean_absolute_error: 16.2110\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 71.9612 - mean_absolute_error: 5.9476\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 41.0430 - mean_absolute_error: 4.2076\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 31.2097 - mean_absolute_error: 3.7048\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 25.8526 - mean_absolute_error: 3.3460\n",
      "41/41 [==============================] - 0s 7ms/step\n",
      "K-FOLD = 1| MSE = 47.187937689990534\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 389.8057 - mean_absolute_error: 17.3231\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 88.9373 - mean_absolute_error: 6.4637\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 40.7089 - mean_absolute_error: 4.1513\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 30.3976 - mean_absolute_error: 3.6171\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 25.7723 - mean_absolute_error: 3.3212\n",
      "41/41 [==============================] - 0s 7ms/step\n",
      "K-FOLD = 2| MSE = 7.50336146936184\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 392.1974 - mean_absolute_error: 17.4333\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 88.8550 - mean_absolute_error: 6.5853\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 38.5211 - mean_absolute_error: 4.0741\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 28.6006 - mean_absolute_error: 3.5148\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 23.8987 - mean_absolute_error: 3.1865\n",
      "41/41 [==============================] - 0s 8ms/step\n",
      "K-FOLD = 3| MSE = 19.949173671443287\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 399.2660 - mean_absolute_error: 17.7715\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 91.5650 - mean_absolute_error: 6.5476\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 46.6619 - mean_absolute_error: 4.3431\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 34.6347 - mean_absolute_error: 3.8141\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 28.4002 - mean_absolute_error: 3.3929\n",
      "41/41 [==============================] - 0s 8ms/step\n",
      "K-FOLD = 4| MSE = 27.405527626595845\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 384.3861 - mean_absolute_error: 17.3027\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 79.2250 - mean_absolute_error: 6.0999\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 41.1905 - mean_absolute_error: 4.2321\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 33.4058 - mean_absolute_error: 3.7268\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 28.4413 - mean_absolute_error: 3.3758\n",
      "40/40 [==============================] - 0s 8ms/step\n",
      "K-FOLD = 5| MSE = 11.115962982177734\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 351.4546 - mean_absolute_error: 16.4794\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 77.1528 - mean_absolute_error: 6.0832\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 40.9558 - mean_absolute_error: 4.0917\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 32.6906 - mean_absolute_error: 3.6016\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 28.5040 - mean_absolute_error: 3.3969\n",
      "40/40 [==============================] - 0s 9ms/step\n",
      "K-FOLD = 6| MSE = 13.688971328735352\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 413.3831 - mean_absolute_error: 18.0235\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 85.4183 - mean_absolute_error: 6.5131\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 43.7383 - mean_absolute_error: 4.2824\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 34.5216 - mean_absolute_error: 3.7673\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 28.9587 - mean_absolute_error: 3.4535\n",
      "40/40 [==============================] - 0s 9ms/step\n",
      "K-FOLD = 7| MSE = 14.047594833374024\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 377.9140 - mean_absolute_error: 17.1864\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 74.9000 - mean_absolute_error: 6.0904\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 34.7620 - mean_absolute_error: 3.9901\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 25.6905 - mean_absolute_error: 3.4008\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 20.7450 - mean_absolute_error: 3.1007\n",
      "40/40 [==============================] - 0s 9ms/step\n",
      "K-FOLD = 8| MSE = 59.27915649414062\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 367.9490 - mean_absolute_error: 17.0708\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 76.5847 - mean_absolute_error: 6.2612\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 38.9501 - mean_absolute_error: 4.1628\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 30.6306 - mean_absolute_error: 3.6197\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 26.2902 - mean_absolute_error: 3.3469\n",
      "40/40 [==============================] - 0s 9ms/step\n",
      "K-FOLD = 9| MSE = 47.642354774475095\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 389.2247 - mean_absolute_error: 17.2771\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 81.6439 - mean_absolute_error: 6.1896\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 41.2278 - mean_absolute_error: 4.0598\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 31.0530 - mean_absolute_error: 3.6579\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 25.6056 - mean_absolute_error: 3.3630\n",
      "40/40 [==============================] - 0s 9ms/step\n",
      "K-FOLD = 10| MSE = 16.56704092025757\n",
      "Layer 1 has 90 nodes - yields MSE = 29.82334406895366\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 366.3202 - mean_absolute_error: 16.6845\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 67.8878 - mean_absolute_error: 5.8083\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 33.9159 - mean_absolute_error: 3.8779\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 26.9916 - mean_absolute_error: 3.4319\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 22.9686 - mean_absolute_error: 3.1547\n",
      "41/41 [==============================] - 0s 9ms/step\n",
      "K-FOLD = 1| MSE = 47.35049008160102\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 388.1256 - mean_absolute_error: 17.2237\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 95.0359 - mean_absolute_error: 6.6231\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 50.3909 - mean_absolute_error: 4.5920\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 35.9675 - mean_absolute_error: 3.8646\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 29.0581 - mean_absolute_error: 3.5261\n",
      "41/41 [==============================] - 0s 11ms/step\n",
      "K-FOLD = 2| MSE = 9.446688558997177\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 336.6091 - mean_absolute_error: 15.9705\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 71.9347 - mean_absolute_error: 5.6358\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 39.9216 - mean_absolute_error: 4.0250\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 29.6846 - mean_absolute_error: 3.4858\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 25.7428 - mean_absolute_error: 3.2521\n",
      "41/41 [==============================] - 0s 10ms/step\n",
      "K-FOLD = 3| MSE = 20.262474641567323\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 380.0877 - mean_absolute_error: 17.0662\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 77.9980 - mean_absolute_error: 5.8798\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 38.3782 - mean_absolute_error: 3.8742\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 29.0722 - mean_absolute_error: 3.3605\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 24.4029 - mean_absolute_error: 3.0865\n",
      "41/41 [==============================] - 0s 10ms/step\n",
      "K-FOLD = 4| MSE = 22.436250686645508\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 374.8748 - mean_absolute_error: 16.9229\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 73.4978 - mean_absolute_error: 5.8656\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 41.7666 - mean_absolute_error: 4.1341\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 31.6349 - mean_absolute_error: 3.7072\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 26.6678 - mean_absolute_error: 3.3130\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "K-FOLD = 5| MSE = 10.243689632415771\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 358.7666 - mean_absolute_error: 16.5129\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 71.2216 - mean_absolute_error: 5.6921\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 42.1954 - mean_absolute_error: 4.1567\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 33.1292 - mean_absolute_error: 3.6317\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 27.2171 - mean_absolute_error: 3.2694\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "K-FOLD = 6| MSE = 12.890487098693848\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 324.0025 - mean_absolute_error: 15.2637\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 68.6359 - mean_absolute_error: 5.3830\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 40.3532 - mean_absolute_error: 4.1045\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 31.7936 - mean_absolute_error: 3.5998\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 27.2447 - mean_absolute_error: 3.2991\n",
      "40/40 [==============================] - 0s 12ms/step\n",
      "K-FOLD = 7| MSE = 10.105840873718261\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 5ms/step - loss: 330.6965 - mean_absolute_error: 15.7113\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 62.7024 - mean_absolute_error: 5.4216\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 33.0322 - mean_absolute_error: 3.8019\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 24.4298 - mean_absolute_error: 3.3247\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 20.3535 - mean_absolute_error: 3.0040\n",
      "40/40 [==============================] - 0s 12ms/step\n",
      "K-FOLD = 8| MSE = 58.750352478027345\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 6ms/step - loss: 393.6060 - mean_absolute_error: 17.5355\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 79.6837 - mean_absolute_error: 6.4030\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 39.1566 - mean_absolute_error: 4.1051\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 29.9051 - mean_absolute_error: 3.5291\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 24.5293 - mean_absolute_error: 3.2506\n",
      "40/40 [==============================] - 0s 12ms/step\n",
      "K-FOLD = 9| MSE = 46.37104415893555\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 6ms/step - loss: 395.1707 - mean_absolute_error: 17.3599\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 86.4620 - mean_absolute_error: 6.3131\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 44.4754 - mean_absolute_error: 4.1591\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 34.2447 - mean_absolute_error: 3.6368\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 29.0058 - mean_absolute_error: 3.3589\n",
      "40/40 [==============================] - 0s 12ms/step\n",
      "K-FOLD = 10| MSE = 18.050336265563963\n",
      "Layer 1 has 100 nodes - yields MSE = 29.218689980191225\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 358.5714 - mean_absolute_error: 16.5735\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 66.5572 - mean_absolute_error: 5.5409\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 33.9681 - mean_absolute_error: 3.9644\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 25.0641 - mean_absolute_error: 3.3455\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 21.3772 - mean_absolute_error: 3.0625\n",
      "41/41 [==============================] - 0s 12ms/step\n",
      "K-FOLD = 1| MSE = 42.753709304623484\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 386.8226 - mean_absolute_error: 17.1822\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 73.3508 - mean_absolute_error: 5.9418\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 40.4982 - mean_absolute_error: 4.2143\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 31.6160 - mean_absolute_error: 3.6461\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 26.9849 - mean_absolute_error: 3.4048\n",
      "41/41 [==============================] - 1s 12ms/step\n",
      "K-FOLD = 2| MSE = 8.568591978491806\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 343.4195 - mean_absolute_error: 16.2463\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 60.9964 - mean_absolute_error: 5.2746\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 35.7792 - mean_absolute_error: 3.8734\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 28.2044 - mean_absolute_error: 3.4266\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 25.1180 - mean_absolute_error: 3.1836\n",
      "41/41 [==============================] - 0s 12ms/step\n",
      "K-FOLD = 3| MSE = 18.790548138502167\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 350.0082 - mean_absolute_error: 16.3038\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 80.2905 - mean_absolute_error: 5.8293\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 40.8740 - mean_absolute_error: 4.0822\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 31.1572 - mean_absolute_error: 3.5476\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 26.2284 - mean_absolute_error: 3.2863\n",
      "41/41 [==============================] - 1s 13ms/step\n",
      "K-FOLD = 4| MSE = 26.83010706087438\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 6ms/step - loss: 350.2428 - mean_absolute_error: 16.1118\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 67.7446 - mean_absolute_error: 5.4938\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 39.0571 - mean_absolute_error: 3.9795\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 31.3459 - mean_absolute_error: 3.5640\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 26.5355 - mean_absolute_error: 3.2782\n",
      "40/40 [==============================] - 1s 14ms/step\n",
      "K-FOLD = 5| MSE = 10.881507682800294\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 2s 6ms/step - loss: 395.4870 - mean_absolute_error: 17.2022\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 83.7889 - mean_absolute_error: 6.1700\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 43.3328 - mean_absolute_error: 4.2752\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 32.2509 - mean_absolute_error: 3.6035\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 25.9879 - mean_absolute_error: 3.3249\n",
      "40/40 [==============================] - 0s 12ms/step\n",
      "K-FOLD = 6| MSE = 13.776421546936035\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 6ms/step - loss: 362.5175 - mean_absolute_error: 16.6239\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 76.1079 - mean_absolute_error: 5.7739\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 37.9565 - mean_absolute_error: 4.0023\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 29.2208 - mean_absolute_error: 3.4809\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 24.6916 - mean_absolute_error: 3.2470\n",
      "40/40 [==============================] - 1s 13ms/step\n",
      "K-FOLD = 7| MSE = 10.749464893341065\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 6ms/step - loss: 354.9462 - mean_absolute_error: 16.3522\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 59.8592 - mean_absolute_error: 5.3869\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 30.1492 - mean_absolute_error: 3.6923\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 23.4508 - mean_absolute_error: 3.2233\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 19.3284 - mean_absolute_error: 2.9983\n",
      "40/40 [==============================] - 1s 13ms/step\n",
      "K-FOLD = 8| MSE = 59.37995300292969\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 6ms/step - loss: 334.2609 - mean_absolute_error: 15.7907\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 63.4523 - mean_absolute_error: 5.4514\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 38.9401 - mean_absolute_error: 4.0576\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 31.0887 - mean_absolute_error: 3.5717\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 25.5139 - mean_absolute_error: 3.2632\n",
      "40/40 [==============================] - 1s 13ms/step\n",
      "K-FOLD = 9| MSE = 58.735365295410155\n",
      "Epoch 1/5\n",
      "364/364 [==============================] - 2s 6ms/step - loss: 350.3779 - mean_absolute_error: 16.1357\n",
      "Epoch 2/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 66.6531 - mean_absolute_error: 5.7046\n",
      "Epoch 3/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 39.4904 - mean_absolute_error: 4.0614\n",
      "Epoch 4/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 30.9866 - mean_absolute_error: 3.5756\n",
      "Epoch 5/5\n",
      "364/364 [==============================] - 1s 3ms/step - loss: 26.5795 - mean_absolute_error: 3.3073\n",
      "40/40 [==============================] - 1s 13ms/step\n",
      "K-FOLD = 10| MSE = 16.34554080963135\n",
      "Layer 1 has 110 nodes - yields MSE = 28.901493854086574\n",
      "With 1 layer optimal node count is: 110\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use functionality to determine optimal node count, given one layer\n",
    "node_sizes = np.arange(40, 120, 10)\n",
    "scores = []\n",
    "for count in node_sizes:\n",
    "    structure = [count]\n",
    "    score = cross_validate(structure)\n",
    "    print(\"Layer 1 has {} nodes - yields MSE = {}\".format(count, score))\n",
    "    scores.append(score)\n",
    "\n",
    "min_mse_size = node_sizes[ np.argmin(scores) ]\n",
    "print(\"With 1 layer optimal node count is:\", min_mse_size)\n",
    "\n",
    "# quick plot of MSE as function of node size\n",
    "plt.plot(node_sizes, scores)\n",
    "plt.xlabel(\"Node Size\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Node Sizes VS Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'Sequential'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-30e3b137dd36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmse_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model {i} with parameters {models[i]} has MSE of {score}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0908a3417af0>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(model_structure)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mval_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0908a3417af0>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(layer_list)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0madd\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     '''\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode_count\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'Sequential'"
     ]
    }
   ],
   "source": [
    "\n",
    "strcutures=[[10,20],[100,200],[10,20,30],[100,200,300],[10,20,30,40],[100,200,300,400]]\n",
    "mse_scores=[]\n",
    "\n",
    "for i,structure in enumerate(structures):\n",
    "    score = cross_validate(structure)\n",
    "    mse_scores.append(score)\n",
    "    print (f\"Model {i} with parameters {structures[i]} has MSE of {score}.\")\n",
    "\n",
    "index_mse = np.argmin(mse_scores)\n",
    "print (structures[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras.regularizers import l2, l1\n",
    "\n",
    "## Part 1\n",
    "### i).\n",
    "\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "N = 100\n",
    "batchsize = 512\n",
    "epoch_count = 200\n",
    "split1 = 1/6\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(512, activation='relu'))\n",
    "network.add(layers.Dense(512, activation='relu'))\n",
    "network.add(layers.Dense(512, activation='relu'))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "train_images = train_images.reshape( (60000, 28 * 28) )\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape( (10000, 28 * 28) )\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "fit = network.fit(train_images, train_labels, epochs=epoch_count, batch_size=batchsize, validation_split=split1)\n",
    "\n",
    "\n",
    "\n",
    "training_error = fit.history['loss']\n",
    "training_acc = fit.history['acc']\n",
    "vali_error = fit.history['val_loss']\n",
    "vali_acc = fit.history['val_acc']\n",
    "x_vals = np.arange(1, epoch_count+1)\n",
    "\n",
    "plt.plot(x_vals, training_acc, 'r',label='Training Accuracy')\n",
    "plt.plot(x_vals, vali_acc, 'b',label='Validation Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy by Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.plot(x_vals, training_error, 'r',label='Training Accuracy')\n",
    "plt.plot(x_vals, vali_error, 'r',label='Validation Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Error by Epoch\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "index_min = np.argmin(vali_error)\n",
    "print(f\"The optimal epoch is {index_min}\".)\n",
    "\n",
    "### ii.\n",
    "\n",
    "drop_network = models.Sequential()\n",
    "\n",
    "drop_network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "drop_network.add(layers.Dropout(0.5))\n",
    "\n",
    "drop_network.add(layers.Dense(512, activation='relu'))\n",
    "drop_network.add(layers.Dropout(0.5))\n",
    "\n",
    "drop_network.add(layers.Dense(512, activation='relu'))\n",
    "drop_network.add(layers.Dropout(0.5))\n",
    "\n",
    "drop_network.add(layers.Dense(512, activation='relu'))\n",
    "drop_network.add(layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "drop_network.add(layers.Dense(10, activation='softmax'))\n",
    "drop_network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "drop_fit = drop_network.fit(train_images, train_labels, epochs=epoch_count, batch_size=batchsize, validation_split=split1)\n",
    "\n",
    "drop_val_error = drop_fit.history['val_loss']\n",
    "drop_val_acc = drop_fit.history['val_acc']\n",
    "x_vals = np.arange(1, epoch_count+1)\n",
    "\n",
    "plt.plot(x_vals, drop_val_error,'r',label='Dropped')\n",
    "plt.plot(x_vals, vali_error,'b',label='Original')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Error\")\n",
    "plt.title(\"Validation Error by epoch\")\n",
    "plt.legend()\n",
    "\n",
    "plt.plot(x_vals, drop_val_acc,'r',label='Dropped')\n",
    "plt.plot(x_vals, vali_acc,'b',label='Original')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Validation Accuracy by epoch\")\n",
    "plt.legend()\n",
    "\n",
    "The new model is doing better. \n",
    "\n",
    "### iii.\n",
    "\n",
    "\n",
    "# build artchicture - L1 regularization# build  \n",
    "# build artchicture\n",
    "\n",
    "l1_network = models.Sequential()\n",
    "l1_network.add(layers.Dense(512, activation='relu', kernel_regularizer=l1(0.001), input_shape=(28 * 28,)))\n",
    "\n",
    "\n",
    "l1_network.add(layers.Dense(512, kernel_regularizer=l1(0.001), activation='relu'))\n",
    "l1_network.add(layers.Dense(512, kernel_regularizer=l1(0.001), activation='relu'))\n",
    "l1_network.add(layers.Dense(512, kernel_regularizer=l1(0.001), activation='relu'))\n",
    "\n",
    "l1_network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# build artchicture - L2 regularization\n",
    "l2_network = models.Sequential()\n",
    "l2_network.add(layers.Dense(512, activation='relu', kernel_regularizer=l2(0.001), input_shape=(28 * 28,)))\n",
    "\n",
    "\n",
    "l2_network.add(layers.Dense(512, kernel_regularizer=l2(0.001), activation='relu'))\n",
    "l2_network.add(layers.Dense(512, kernel_regularizer=l2(0.001), activation='relu'))\n",
    "l2_network.add(layers.Dense(512, kernel_regularizer=l2(0.001), activation='relu'))\n",
    "\n",
    "\n",
    "l2_network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# Fit the model# Fit th \n",
    "l1_network.compile(optimizer='rmsprop', loss='categorical_crossentropy',  metrics=['acc'])\n",
    "l1_fit = l1_network.fit(train_images, train_labels, epochs=epoch_count, batch_size=batchsize, validation_split=split1)\n",
    "\n",
    "l2_network.compile(optimizer='rmsprop', loss='categorical_crossentropy',  metrics=['acc'])\n",
    "l2_fit = l2_network.fit(train_images, train_labels, epochs=epoch_count, batch_size=batchsize, validation_split=split1)\n",
    "\n",
    "\n",
    "# Plot the training losses of all 4 models# Plot t \n",
    "l1_val_error = l1_fit.history['val_loss']\n",
    "l1_val_acc = l1_fit.history['val_acc']\n",
    "\n",
    "l2_val_error = l2_fit.history['val_loss']\n",
    "l2_val_acc = l2_fit.history['val_acc']\n",
    "\n",
    "plt.plot(x_vals, drop_val_error, label='Dropped' )\n",
    "plt.plot(x_vals, vali_error, label='Original')\n",
    "plt.plot(x_vals, l1_val_error, label='L1')\n",
    "plt.plot(x_vals, l2_val_error, label='L2')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation error\")\n",
    "plt.title(\"Validation error by Epoch across Models\")\n",
    "plt.legend()\n",
    "\n",
    "min1=np.min(drop_val_error)\n",
    "min2=np.min(vali_error)\n",
    "min3=np.min(l1_val_error)\n",
    "min4=np.min(l2_val_error)\n",
    "min1,min2,min3,min4\n",
    "\n",
    "The best model is \n",
    "\n",
    "new_epoch_count =  np.argmin(vali_error) + 1\n",
    "print(\"The optimal epoch for the main baseline model is:\", new_epoch_count)\n",
    "\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "full_fit = network.fit(train_images, train_labels, epochs=new_epoch_count, batch_size=batchsize)\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "print(\"Test loss:\", test_loss)\n",
    "\n",
    "## Part 2\n",
    "\n",
    "from keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std \n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std\n",
    "\n",
    "def build_model(layer_list):\n",
    "    '''\n",
    "    The layer_list is a list of integers, each denoting a layer to\n",
    "    add with the corresponding number of nodes\n",
    "    '''\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    for node_count in layer_list:\n",
    "        model.add(layers.Dense(node_count, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def cross_validate(model_structure):\n",
    "    '''\n",
    "    Given a model structure, returns the avg MSE over 10 k-fold\n",
    "    cross validation training\n",
    "    \n",
    "    This facilitates rapid testing of models\n",
    "    '''\n",
    "    \n",
    "    kf = KFold(n_splits = k)\n",
    "    cur_fold = 0\n",
    "    for train_index, test_index in kf.split(train_data):\n",
    "        cur_fold +=1 \n",
    "\n",
    "        # Partition the data\n",
    "        x_train, x_test = train_data[train_index], train_data[test_index]\n",
    "        y_train, y_test = train_targets[train_index], train_targets[test_index]\n",
    "\n",
    "\n",
    "        model = build_model(model_structure)\n",
    "        model.fit(x_train, y_train, epochs=num_epochs, batch_size=1)\n",
    "        val_mse, val_mae = model.evaluate(x_test, y_test)\n",
    "        all_scores.append(val_mse)\n",
    "        print(\"K-FOLD = {}| MSE = {}\".format(cur_fold, val_mse ))\n",
    "\n",
    "    mean_score = np.mean(all_scores)\n",
    "    return mean_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "k = 10\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 5\n",
    "all_scores = []\n",
    "\n",
    "# Use functionality to determine optimal node count, given one layer\n",
    "node_sizes = np.arange(40, 120, 10)\n",
    "scores = []\n",
    "for count in node_sizes:\n",
    "    structure = [count]\n",
    "    score = cross_validate(structure)\n",
    "    print(\"Layer 1 has {} nodes - yields MSE = {}\".format(count, score))\n",
    "    scores.append(score)\n",
    "\n",
    "min_mse_size = node_sizes[ np.argmin(scores) ]\n",
    "print(\"With 1 layer optimal node count is:\", min_mse_size)\n",
    "\n",
    "# quick plot of MSE as function of node size\n",
    "plt.plot(node_sizes, scores)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "models=[[10,20],[100,200],[10,20,30],[100,200,300],[10,20,30,40],[100,200,300,400]\n",
    "mse_scores=[]\n",
    "\n",
    "for i,model in enumerate(models):\n",
    "    score = cross_validate(model)\n",
    "    mse_scores.append(score)\n",
    "    print (f\"Model {i} with parameters {models[i]} has MSE of {score}.\")\n",
    "\n",
    "index_mse = np.argmin(mse_scores)\n",
    "print (models[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
